{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOwnOTFai2xv6J5IEMewfZg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Chandana-Myakala/NLP/blob/main/Assignment6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load data fromkeras.datasets and perform following computational analysis:- [CO3]\n",
        "(a) Preprocessing of the Data\n",
        "\n",
        "(b) Divide data into training and testing data set\n",
        "\n",
        "(c) Build the Gated Recurrent Units (GRU) Model\n",
        "\n",
        "(d) Training the GRU Model\n",
        "\n",
        "(e) Text Generation Using the Trained Model\n",
        "\n",
        " (f)  Evaluate Model’s accuracy"
      ],
      "metadata": {
        "id": "RTT5NAJMUzp1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gSaMvFpFX7lD",
        "outputId": "1020847c-99af-4fc3-949f-d97dd20732b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.11.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.0)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.9.2)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.13.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (3.0.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, GRU, LSTM, Dense\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "ihRlS2ofYC45"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Load and Preprocess Data (using IMDB dataset)\n",
        "from tensorflow.keras.datasets import imdb\n",
        "\n",
        "# Set parameters for text processing\n",
        "vocab_size = 10000  # Restrict vocabulary to 10k most frequent words\n",
        "max_length = 200  # Maximum length of sequences\n",
        "\n",
        "# Load IMDB dataset\n",
        "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=vocab_size)\n",
        "\n",
        "# Pad sequences to ensure uniform length for all input data\n",
        "X_train = pad_sequences(X_train, maxlen=max_length, padding='post')\n",
        "X_test = pad_sequences(X_test, maxlen=max_length, padding='post')"
      ],
      "metadata": {
        "id": "A2v4j4juYG9o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Build the GRU model\n",
        "def build_gru_model(vocab_size, max_length):\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(vocab_size, 128, input_length=max_length))\n",
        "    model.add(GRU(128, return_sequences=True))  # First GRU layer with return_sequences\n",
        "    model.add(GRU(128))  # Second GRU layer\n",
        "    model.add(Dense(1, activation='sigmoid'))  # Output layer for binary classification\n",
        "    return model\n",
        "\n",
        "# Initialize GRU model\n",
        "gru_model = build_gru_model(vocab_size, max_length)"
      ],
      "metadata": {
        "id": "0PfzaJiFYPN5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Train the GRU model\n",
        "gru_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "gru_history = gru_model.fit(X_train, y_train, epochs=3, batch_size=64, validation_data=(X_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DAX8W2xeYT7f",
        "outputId": "49b49383-341d-4292-c50a-a74ab173110b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m554s\u001b[0m 1s/step - accuracy: 0.5287 - loss: 0.6963 - val_accuracy: 0.7237 - val_loss: 0.5677\n",
            "Epoch 2/3\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m518s\u001b[0m 1s/step - accuracy: 0.7915 - loss: 0.4544 - val_accuracy: 0.8044 - val_loss: 0.4306\n",
            "Epoch 3/3\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m562s\u001b[0m 1s/step - accuracy: 0.8629 - loss: 0.3273 - val_accuracy: 0.8650 - val_loss: 0.3162\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenizer to convert sequence back to text\n",
        "tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
        "\n",
        "# Convert X_train from array to list of strings\n",
        "X_train_str = [' '.join(map(str, sequence)) for sequence in X_train]\n",
        "\n",
        "# Fit tokenizer on the converted list of strings\n",
        "tokenizer.fit_on_texts(X_train_str)"
      ],
      "metadata": {
        "id": "-yb3vcz-fqnB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Text Generation using the trained GRU model\n",
        "def generate_text(model, tokenizer, seed_text, max_sequence_len):\n",
        "    for _ in range(50):  # Generate 50 words\n",
        "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "        token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "        predicted = model.predict(token_list, verbose=0)\n",
        "        output_word = ''\n",
        "        for word, index in tokenizer.word_index.items():\n",
        "            if index == np.argmax(predicted):\n",
        "                output_word = word\n",
        "                break\n",
        "        seed_text += \" \" + output_word\n",
        "    return seed_text\n",
        "\n",
        "# Tokenizer to convert sequence back to text\n",
        "tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
        "\n",
        "# Convert X_train from array to list of strings\n",
        "X_train_str = [' '.join(map(str, sequence)) for sequence in X_train]\n",
        "\n",
        "# Fit tokenizer on the converted list of strings\n",
        "tokenizer.fit_on_texts(X_train_str)\n",
        "\n",
        "# Generate text using the trained GRU model\n",
        "seed_text = \"The movie was\"\n",
        "generated_text = generate_text(gru_model, tokenizer, seed_text, max_length)\n",
        "print(f\"Generated Text (GRU): {generated_text}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cqBRyrOhfu2t",
        "outputId": "bb3ecb1b-d9f8-4b71-cd59-1a1aaccb5222"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Text (GRU): The movie was                                                  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6: Evaluate GRU model accuracy\n",
        "gru_test_loss, gru_test_accuracy = gru_model.evaluate(X_test, y_test)\n",
        "print(f\"GRU Model Accuracy: {gru_test_accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ljf8ZrYeaX7X",
        "outputId": "2da86452-8ff0-4693-b232-4bf586a86ab3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 118ms/step - accuracy: 0.8629 - loss: 0.3215\n",
            "GRU Model Accuracy: 0.8650400042533875\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compare accuracy of Long sort term memory and Gated recurrent Unit models for text generation using data from tensorflow.keras.datasets. [CO3]"
      ],
      "metadata": {
        "id": "ZhAR67sThImZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 7: Build the LSTM Model for comparison\n",
        "def build_lstm_model(vocab_size, max_length):\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(vocab_size, 128, input_length=max_length))\n",
        "    model.add(LSTM(128, return_sequences=True))  # First LSTM layer with return_sequences\n",
        "    model.add(LSTM(128))  # Second LSTM layer\n",
        "    model.add(Dense(1, activation='sigmoid'))  # Output layer for binary classification\n",
        "    return model\n",
        "\n",
        "# Initialize LSTM model\n",
        "lstm_model = build_lstm_model(vocab_size, max_length)\n",
        "\n",
        "# Train the LSTM model\n",
        "lstm_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "lstm_history = lstm_model.fit(X_train, y_train, epochs=3, batch_size=64, validation_data=(X_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uibHfSmKabjd",
        "outputId": "338a8d54-84ae-4e7c-f9e6-9e107fcfd9f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m512s\u001b[0m 1s/step - accuracy: 0.5696 - loss: 0.6669 - val_accuracy: 0.5216 - val_loss: 0.6925\n",
            "Epoch 2/3\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m493s\u001b[0m 1s/step - accuracy: 0.6128 - loss: 0.6347 - val_accuracy: 0.7870 - val_loss: 0.4852\n",
            "Epoch 3/3\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m498s\u001b[0m 1s/step - accuracy: 0.8264 - loss: 0.4202 - val_accuracy: 0.8531 - val_loss: 0.3500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 8: Evaluate LSTM model accuracy\n",
        "lstm_test_loss, lstm_test_accuracy = lstm_model.evaluate(X_test, y_test)\n",
        "print(f\"LSTM Model Accuracy: {lstm_test_accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQyVH5H4agio",
        "outputId": "b90ffdbf-acc6-4974-db17-1abb545cbcd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 228ms/step - accuracy: 0.8517 - loss: 0.3506\n",
            "LSTM Model Accuracy: 0.8530799746513367\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 9: Compare GRU and LSTM models\n",
        "print(f\"GRU Accuracy: {gru_test_accuracy}, LSTM Accuracy: {lstm_test_accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KzeF5KDlakVm",
        "outputId": "e81ce94e-8a86-4da2-98d4-3f51b994cc69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GRU Accuracy: 0.8650400042533875, LSTM Accuracy: 0.8530799746513367\n"
          ]
        }
      ]
    }
  ]
}